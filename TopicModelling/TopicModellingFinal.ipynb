{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with Matrix Decomposition\n",
    "\n",
    "#### Authors: Theophil Trippe and Sahil Karkhanis\n",
    "\n",
    "In this Jupyter Notebook, we present an approach to Topic Modelling using a basic linear algebra concept called **Singular Value Decomposition** with a little demonstration. This notebook is written in order to allow an interactive familiarization with the concept.\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](MatVellosoQuote.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling: \n",
    "- NLP (Natural language processing) and \n",
    "- **not** Text Classification                       \n",
    "    - supervised learning\n",
    "    - you know topics beforehand\n",
    "    - topics are cathegorize into those given topics\n",
    "    - Naive Bayes, Support Vector Machines or logistic regression.\n",
    "- Topic Modelling\n",
    "    - unsupervised learning\n",
    "    - learns topics (in form of weighted words)\n",
    "    - learn a distribution of the documents into those topics\n",
    "    - learns the overall relevance (across all documents) of each topic\n",
    "    - allows quick classification of out-of-sample documents\n",
    "                             \n",
    "                             \n",
    "\n",
    "#### Use Cases:\n",
    "\n",
    "- Alternative to Text Classification when there is a lack of labeled data\n",
    "- Client wants to analyze user requests (e.g. telecommunication company): \n",
    " - *What* are the common topics concerning the customer? (e.g. billing, contract, service problems, etc.)\n",
    " - Do those topics *match* with the clients perception?\n",
    " - On what topics should the client allocate more capacities because the topic has a *high overall relevance*\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing (Bag-of-Words approach)\n",
    "\n",
    "Consider this dataset consisting of two documents where each document consists of just one sentence:\n",
    "\n",
    "Document 1 | Document 2\n",
    "---|---\n",
    "This is a sentence about a dog. | Today we are talking about cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *bag-of-words* approach simply counts which word occurs how many times in a sentence. Therefore disregarding word-order or sentence structure:\n",
    "\n",
    "Document 1 | Document 2\n",
    "---|---\n",
    "This is a sentence about a dog. | Today we are talking about cats\n",
    "This (1) |\n",
    "is (1) |\n",
    "a (2) |\n",
    "sentence (1) |\n",
    "about (1) |\n",
    "dog (1) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering all documents, we obtain the vocabulary of our dataset and assign a value to each (word, document)-pair:\n",
    "\n",
    "Vocabulary | Document 1 | Document 2\n",
    "--- | ---|---\n",
    " | This is a sentence about a dog. | Today we are talking about cats\n",
    "*This* | 1 | 0\n",
    "*is* | 1 | 0\n",
    "*a* | 2 | 0\n",
    "*sentence* | 1 | 0\n",
    "*about* | 1 | 1\n",
    "*dog* | 1 | 0\n",
    "*Today* | 0 | 1\n",
    "*we* | 0 | 1\n",
    "*are* | 0 | 1\n",
    "*talking* | 0 | 1\n",
    "*cats* | 0 | 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actually lose the information containing sentence structure and word-order of our documents completely, leaving us with a matrix containing all relevant information (here with an alphabetically ordered vocab):\n",
    "\n",
    "Vocabulary | Document 1 | Document 2\n",
    "--- | ---|---\n",
    "*a* | 2 | 0\n",
    "*about* | 1 | 1\n",
    "*are* | 0 | 1\n",
    "*cats* | 0 | 1\n",
    "*dog* | 1 | 0\n",
    "*is* | 1 | 0\n",
    "*question* | 1 | 0\n",
    "*talking* | 0 | 1\n",
    "*this* | 1 | 0\n",
    "*today* | 0 | 1\n",
    "*we* | 0 | 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our approach to Topic Modeling (SVD)\n",
    "\n",
    "Once the data is transformed into a matrix, we use **Singular Value Decomposition (SVD)**, to decompose the matrix into three matrices $U, S$ and $V$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](SVD_visualization.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then interpret the different components of this new representation of our data in the following way:\n",
    "\n",
    "+ **before**:  words per document\n",
    "\n",
    "+ **after**:  (words per topic) (overall relevance of topics) (topics per document)\n",
    "\n",
    "+ **columns of S**: topics, represented by the relevance of each word of the vocabulary\n",
    "\n",
    "+ **columns of $\\Sigma V$**: indexing the relative relevance of each topic for some specific document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration\n",
    "\n",
    "\n",
    "SciKitLearn provides build-in datasets: The **20 Newsgroups dataset** contains around 18000 newsgroup posts on 20 different topics. Newsgroups are discussion groupsin the Usenet, so you can think about it as internet forums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn import decomposition\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching and Cleaning the Data\n",
    "\n",
    "There are roughly 11000 documents in the training data and 20 different topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = fetch_20newsgroups()\n",
    "print(example.filenames.shape)\n",
    "example.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only use the data corresponding to 4 of those topics for the purpose of this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "example = fetch_20newsgroups(subset='train', categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at one of the documents we have now, we can see that there is still a lot of information that we don't need in the header and in the footer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: rych@festival.ed.ac.uk (R Hawkes)\n",
      "Subject: 3DS: Where did all the texture rules go?\n",
      "Lines: 21\n",
      "\n",
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "\n",
      "======================================================================\n",
      "Rycharde Hawkes\t\t\t\temail: rych@festival.ed.ac.uk\n",
      "Virtual Environment Laboratory\n",
      "Dept. of Psychology\t\t\tTel  : +44 31 650 3426\n",
      "Univ. of Edinburgh\t\t\tFax  : +44 31 667 0150\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(example.data[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove those automatically using the *remove* parameter included in fetch_20newsgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove= ('headers', 'footers', 'quotes')) #only the posts belonging to the specified cathegories where headers, footers and quotes are removed (cleaning the data) are included\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories,remove= ('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data now has a much cleaner look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(newsgroups_train.data[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "The next step will be, to transform each post into a vector. This step can be combined with other Data preprocessing. Some of the options are the following:\n",
    "\n",
    "\n",
    "### Data Cleaning (Removing Stopwords and Stemming)\n",
    "1. We can remove *stop-words*, so words (like \"this\", \"and\", \"then\", etc...) that don't provide insight about the occuring topics (in the bag of words approach, since we've lost the context of those words)\n",
    "\n",
    "coming back to our previous example, it would reduce our data to this:\n",
    "\n",
    "Vocabulary | Document 1 | Document 2\n",
    "--- | ---|---\n",
    "*cats* | 0 | 1\n",
    "*dog* | 1 | 0\n",
    "*question* | 1 | 0\n",
    "*talking* | 0 | 1\n",
    "*today* | 0 | 1\n",
    "\n",
    "\n",
    "2. We can use a *stemmer*, which is an algorithm that reduces words to their stem (*e.g.: fisher, fishing, fished, fish $\\rightarrow$ fish*) adding up the occuring instances of each version of the word\n",
    "\n",
    "\n",
    "Those two operations drastically reduce the number of words in the vocabulary without losing information about the topics (assuming the stemmer works correctly), therefore improving the perfomance of the decomposition (later). There are several types of Stemming Algorithms that vary in terms of perfomance and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing (using CountVectorizer or TfidfVectorizer)\n",
    "\n",
    "Sklearn provides a few *vectorizer* as part of its feature_extraction tools to transform each document into a vector. (And therefore the dataset into a matrix.)\n",
    "There are several ways to go, depending on the use case:\n",
    "\n",
    "The straight forward approach (like in the cats and dogs example), is to simply count the number of appearances for each word, for that we can use the\n",
    "\n",
    "3. a) Token counts:\n",
    "      - **CountVectorizer**\n",
    "      - straight forward\n",
    "      - counts number of appearances of each word (in a specific document)\n",
    "      - like in the cats and dogs example above\n",
    "    \n",
    "   b) Term frequency (adjusted for document length):\n",
    "      - **TfidfVectorizer** with **use_idf = False**\n",
    "      - Token counts devided by number of words in document\n",
    "      - Use-case example: \"Is a long and detailed user request more relevant than a short one?\"\n",
    "      - e.g. 10 documents, 9 with 50 words, 1 with 5000 words where *\"fish\"* appears 100 times: Are fish now an important topic overall or not?\n",
    " \n",
    "   c) Term frequency and invers document frequency:\n",
    "      - **TfidfVectorizer**\n",
    "      - The weight of a word in a document is antiproportional to the amount of documents the word appears in\n",
    "      - e.g. \"the\" may appear a lot in a document, but since that's the case for all documents, we should not give it too much weight\n",
    "      - Use-case example: You may get a clearer distinction of topics for the different documents, but if a topic is relevant for many users, this approach would be hiding that fact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Possible Combinations\n",
    "\n",
    "Here are just a few possible combinations, using the SnowballStemmer from nltk, note that the stemmer takes a few seconds to work its magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "\n",
    "class SnowToke(object):\n",
    "     def __init__(self):\n",
    "        self.wnl = EnglishStemmer(ignore_stopwords=True)\n",
    "     \n",
    "     def __call__(self, doc):\n",
    "        return [self.wnl.stem(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CountVectorizer (using stemming and discarding stop-words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(tokenizer= SnowToke(), stop_words= {'english'})\n",
    "%time DocPerWord1 = vectorizer1.fit_transform(newsgroups_train.data).todense()\n",
    "DocPerWord1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TfidfVectorizer (using stemming and discarding stop-words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer(tokenizer= SnowToke(), stop_words= {'english'})\n",
    "%time DocPerWord2 = vectorizer2.fit_transform(newsgroups_train.data).todense()\n",
    "DocPerWord2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Term frequency adjusted for document length (using stemming and discarding stop-words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer3 = TfidfVectorizer(tokenizer= SnowToke(), stop_words= {'english'}, use_idf=False)\n",
    "%time DocPerWord3 = vectorizer3.fit_transform(newsgroups_train.data).todense()\n",
    "DocPerWord3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CountVectorizer without stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 26576)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer4 = CountVectorizer(stop_words = 'english')\n",
    "DocPerWord4= vectorizer4.fit_transform(newsgroups_train.data).todense() # (documents, vocab)\n",
    "DocPerWord4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectorizers used actually create a documents per words matrix. In order to comply with the schematic introduction above we need to transpose that matrix. *(Also choose which one of the options above you want to use to proceed)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordPerDoc = np.transpose(DocPerWord4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now *WordPerDoc* is the matrix, where the columns are the document-vectors.\n",
    "since we have fitted the vectorizer we can also get the vocabulary in the same order (alphabetic) as associated in *vectors* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26576,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(vectorizer4.get_feature_names())\n",
    "vocab.shape #contains the remaining vocabulary in the same order as the matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['egregious', 'egrep', 'egress', 'egret', 'egs', 'egsgate', 'egypt',\n",
       "       'egyptian', 'egyptians', 'eh', 'ehb', 'eickemeyer', 'eicn',\n",
       "       'eidetic', 'eiffel', 'eighth', 'eighties', 'eindprodukten',\n",
       "       'eindstadia', 'einen'], dtype='<U80')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[9000:9020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition\n",
    "![title](SVD_visualization.jpg)\n",
    "We can now get to the decomposition, using scipy.linalg's svd which does the job for us. Using *%time* we can see how long the calculation took:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%time U, S, V = linalg.svd(WordPerDoc, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26576, 2034) (2034,) (2034, 2034)\n"
     ]
    }
   ],
   "source": [
    "print(U.shape, S.shape, V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that apart from some numerical deviation, U,S,V really is a **decomposition** of our data matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(U @ np.diag(S) @ V, vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, the columns of $U$ are orthogonal, which is a mathematical way of saying that any two topics are maximally different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose( np.transpose(U) @ U, np.eye(2034) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment we have 2034 topics for 2034 documents - which does not seem like a good way of modelling topics - but the model doesn't just assign a topic to each document, instead each document is composed of many different topics, each having an individual weight in that specific document. The overall relevance of each topic is encoded in $s$ and sorted in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a53840b240>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAGXBJREFUeJzt3X2MHPd93/H3d2bvibzj85GiSdqUbNqWEMSSTDtMHBuNlSqynJjKgwqlacW6qoUgdmvDKRKlRtMUKFCrD3YqJFCqRoIpQ4nt2DFEGHJsQZaqFLAlkXqWKIuULIln0uSJz+Q97u63f8xv75Z3Ozt7x9uHWX1ewGJmfzO7++Xs8TO//e3sjLk7IiLSvaJ2FyAiIs2loBcR6XIKehGRLqegFxHpcgp6EZEup6AXEelyCnoRkS6noBcR6XIKehGRLldodwEA69at861bt7a7DBGRXNm3b9+b7j6ctV5HBP3WrVvZu3dvu8sQEckVM3u9kfU0dCMi0uUU9CIiXU5BLyLS5RT0IiJdTkEvItLlFPQiIl1OQS8i0uVyHfRPvHaCL33/x0wVy+0uRUSkY+U66Pe9fpI7fnCQYllBLyKSJtdBb2Gq65uLiKTLd9CHpFfOi4iky3fQz/TpRUQkTa6DvsI1diMikirXQa+hGxGRbLkO+gp16EVE0uU66E1dehGRTPkO+jB1Jb2ISKp8B32lQ6+cFxFJle+gD1PlvIhIunwHvek4ehGRLA0HvZnFZvaUmX0n3L/UzB4zswNm9nUz6w3tfeH+wbB8a3NKn6Xj6EVE0i2kR/9ZYH/V/duBL7v7NuAkcEtovwU46e7vAr4c1msKHXQjIpKtoaA3s83Ax4G/DvcN+CjwzbDKbuCGML8z3Ccsv8aaNMaik5qJiGRrtEf/58AfAZXzAa8FTrl7MdwfATaF+U3AIYCw/HRYf+mF/YcOrxQRSZcZ9Gb268Axd99X3VxjVW9gWfXz3mpme81s7+joaEPFznuO1GcXEZGKRnr0HwI+YWavAV8jGbL5c2CVmRXCOpuBw2F+BNgCEJavBE7MfVJ3v8vdt7v79uHh4UUVrzF6EZFsmUHv7n/i7pvdfStwE/ADd/894GHgd8Jqu4D7w/yecJ+w/AfepMNiKqcp1hi9iEi6izmO/o+Bz5vZQZIx+LtD+93A2tD+eeC2iysx3WyPXkkvIpKmkL3KLHd/BHgkzL8KfLDGOhPAjUtQWyb9XEpEJFuufxlboaEbEZF0uQ56fRkrIpIt30E/82Wsol5EJE2ugx6dplhEJFOug15fxoqIZMt30JuOoxcRyZLvoA9THUcvIpIu30GvsRsRkUy5DvoKDd2IiKTLddDrOHoRkWz5DnodRy8ikinfQa8evYhIplwHfYU69CIi6XId9LOXolXSi4ikyXfQh6l69CIi6fId9DqOXkQkU66DvkIdehGRdLkOel0zVkQkW76DXteMFRHJlO+gD1P16EVE0uU76HXhERGRTLkO+kqfXkM3IiLpch306tGLiGTLd9C3uwARkRzIddCLiEi2XAe9rhkrIpIt30EfpvoyVkQkXb6DXl/Giohk6o6gb28ZIiIdLd9Br0sJiohkynXQox69iEimXAe9znUjIpIt30GvK4+IiGTKddDPUpdeRCRNroNeQzciItnyHfT6MlZEJFO+g16XEhQRyZQZ9GbWb2aPm9kzZvaCmf3n0H6pmT1mZgfM7Otm1hva+8L9g2H51mYVP/vLWCW9iEiaRnr0k8BH3f19wJXAdWa2A7gd+LK7bwNOAreE9W8BTrr7u4Avh/WaYvZcNyIikiYz6D1xLtztCTcHPgp8M7TvBm4I8zvDfcLya6xZx0HqXDciIpkaGqM3s9jMngaOAQ8CrwCn3L0YVhkBNoX5TcAhgLD8NLC2xnPeamZ7zWzv6Ojoooo3XXpERCRTQ0Hv7iV3vxLYDHwQuLzWamFaK33n9bnd/S533+7u24eHhxutt3Z9GrwREUm1oKNu3P0U8AiwA1hlZoWwaDNwOMyPAFsAwvKVwImlKHYu0yC9iEimRo66GTazVWF+APhVYD/wMPA7YbVdwP1hfk+4T1j+A2/SYTHKeRGRbIXsVdgI7DazmGTH8A13/46ZvQh8zcz+C/AUcHdY/27gq2Z2kKQnf1MT6gZ0KUERkUZkBr27PwtcVaP9VZLx+rntE8CNS1JdhtlfxirpRUTS5PyXsQn16EVE0uU76HWuGxGRTLkO+tpHcoqISLWcB31C57oREUmX66DX0I2ISLZ8B31lRkkvIpIq30FfOY5eSS8ikirfQR+mGqIXEUmX76DXaYpFRDLlO+grlxJscx0iIp0s30Gvw+hFRDLlOugrdBy9iEi67gj6dhcgItLBch30+jJWRCRbvoNelx4REcmU76BXj15EJFN3BH17yxAR6Wj5Dnp0KUERkSz5DnpdSlBEJFO+g77dBYiI5ECug75CQzciIulyHfSV0xSXlfQiIqlyHfSFKAn6UllBLyKSJtdBH4egLyroRURS5TroC7F69CIiWfId9FFSvnr0IiLpch70oUdfKre5EhGRzpXroI9jjdGLiGTJddDrqBsRkWy5DnoddSMiki3fQR9+MFUsKehFRNLkO+grQzf6ZayISKpcB72ZERmUNXQjIpIq10EPSa9ePXoRkXS5D/rITD16EZE6ch/0hch01I2ISB2ZQW9mW8zsYTPbb2YvmNlnQ/saM3vQzA6E6erQbmZ2h5kdNLNnzezqpv4DItNx9CIidTTSoy8Cf+julwM7gE+b2RXAbcBD7r4NeCjcB/gYsC3cbgXuXPKqq8SR6Xz0IiJ1ZAa9ux9x9yfD/FlgP7AJ2AnsDqvtBm4I8zuBez3xI2CVmW1c8sqDgnr0IiJ1LWiM3sy2AlcBjwEb3P0IJDsDYH1YbRNwqOphI6GtKSJT0IuI1NNw0JvZIPAt4HPufqbeqjXa5iWxmd1qZnvNbO/o6GijZcwTq0cvIlJXQ0FvZj0kIX+fu/99aD5aGZIJ02OhfQTYUvXwzcDhuc/p7ne5+3Z33z48PLzY+pMevcboRURSNXLUjQF3A/vd/UtVi/YAu8L8LuD+qvabw9E3O4DTlSGeZijEOo5eRKSeQgPrfAj4l8BzZvZ0aPsPwBeBb5jZLcAbwI1h2QPA9cBBYAz45JJWPEdsOo5eRKSezKB39/9H7XF3gGtqrO/Apy+yroZFOrxSRKSu3P8yNtZRNyIideU/6CNDl4wVEUnXJUGvpBcRSZP7oI8iQxeYEhFJl/ugj3XhERGRunIf9IUo0pexIiJ15D7oowgFvYhIHbkPel1KUESkvtwHvc5eKSJSX+6DXuejFxGpL/dBH0eRznUjIlJH7oO+J9YPpkRE6sl90MeRzl4pIlJP7oNeY/QiIvXlPujjKKKocyCIiKTKfdD3xEZRY/QiIqlyH/S6OLiISH25D/qCvowVEakr90GvMXoRkfpyH/QFjdGLiNSV/6DXGL2ISF1dEfQaoxcRSZf7oI+jCHedk15EJE3ug74QG4DG6UVEUuQ/6KMk6NWjFxGpLfdBH0eVHr2CXkSkltwHfaVHr2PpRURqy33QL+srAHBmfLrNlYiIdKbcB/2mVQMAHDk90eZKREQ6U+6Dfqg/6dGfnyy2uRIRkc6U+6BfHoZuzk8p6EVEasl90A+GoD+nHr2ISE25D/qZHr2CXkSkptwH/bKeGIBzk6U2VyIi0plyH/RRZGxY0cdP3jzf7lJERDpS7oMeYPPqZZw8P9XuMkREOlJXBP2y3pgxHXUjIlJTZtCb2T1mdszMnq9qW2NmD5rZgTBdHdrNzO4ws4Nm9qyZXd3M4iuSoNcYvYhILY306L8CXDen7TbgIXffBjwU7gN8DNgWbrcCdy5NmfUt7y3oOHoRkRSZQe/ujwIn5jTvBHaH+d3ADVXt93riR8AqM9u4VMWmGeiNGVePXkSkpsWO0W9w9yMAYbo+tG8CDlWtNxLa5jGzW81sr5ntHR0dXWQZieV9Bc7r8EoRkZqW+stYq9FW8/zB7n6Xu2939+3Dw8MX9aLLemPGp0u6+IiISA2LDfqjlSGZMD0W2keALVXrbQYOL768xizrTX40NT6tXr2IyFyLDfo9wK4wvwu4v6r95nD0zQ7gdGWIp5mW9SanQdAhliIi8xWyVjCzvwX+CbDOzEaA/wR8EfiGmd0CvAHcGFZ/ALgeOAiMAZ9sQs3zLO9LevRjkyUYasUriojkR2bQu/vvpiy6psa6Dnz6YotaqIEenapYRCRNV/wyttKj1yGWIiLzdUXQV8boz+pUxSIi83RF0L9tVT8Ah0+Nt7kSEZHO0xVBv2Gon95CxBvHx9pdiohIx+mKoI8iY8vqAV5X0IuIzNMVQQ+wfqif4+cn212GiEjH6Zqg16mKRURq656g7yso6EVEauiaoF832MuR0+NM6Hw3IiIX6Jqg/5X3rGdiuswPXzne7lJERDpK1wT9z29eCcAro+faXImISGfpmqBfOdDDUF+BN07oEEsRkWpdE/RmxpY1yxT0IiJzdE3QA1y+cQWP/+QEZV1pSkRkRlcF/Y7L1jA2VeKJ1+Zey1xE5K2rq4L+o+9NrlH+9KFTba5ERKRzdFXQrx3s44qNK/jmvhGSa6CIiEhXBT3Apz5yKQeOnWPPM02/JrmISC50XdB/4n2buHzjCm7/7ku64pSICF0Y9HFk/MePX87h0xP86f3Pt7scEZG267qgB/ild63jUx++lL/bN8LDLx1rdzkiIm3VlUEP8IfXvodt6wf5g/ue5Hsv/Kzd5YiItE3XBn1/T8x9/+YXePclQ/zbv3mKB1882u6SRETaomuDHmD9in6+8q8+wGXDy/nUvXu585FX2l2SiEjLdXXQA6xe3suez/wy116xgdv/4SX+6wP7GZsqtrssEZGW6fqgB+gtRNz5L97PTR/Ywv9+9FV+5X88wjeeOERJ58QRkbeAt0TQQ3LY5Rd/++f55u//IhtXDvBH33qWj9/xjzz68mi7SxMRaaq3TNBXbN+6hm//wS/xF//8Ks5PFbn5nse5+Z7H+eErxymWyu0uT0RkyVknnBNm+/btvnfv3pa/7mSxxFd/+Dp3PHSAMxNF1i7vZeeVm7hx+2bee8kQZtbymkREGmVm+9x9e+Z6b+Wgrzg3WeTRl0f5zrOHefDFo0yXnOGhPq69YgPvf8dqdly2lo0r+xX8ItJRFPSLdPzcJN9/8Sj/eGCUh18aZXw6OV/OusFeLt+4ItyGeO8lK3jn8CC9hbfc6JeIdAgF/RIolZ39R86w7/WTPPfT07z0szO8fPQcU8VkLL8nNt45PMi2DUNsXj0QbsvYvHqATasG6O+J2/wvEJFu1mjQF1pRTF7FkfFzm1byc5tWzrQVS2VeffM8+4+cYf+Rs+w/coZnDp3iH54/wnTpwp3m2uW9XLKyn0tW9LNhZT8bhvpZv6KPDSv6WD/Uz/qhPlYv76Un1qcCEWkeBf0CFeKId28Y4t0bhth55Wx7qewcPTPBT0+NM3JyjEMnxjlyeoKfnR7n8OkJnjp0ihPnp2o+54r+AmsH+1i7vJc1y3tZO5hMVy/rZeVAD6vCtHJbMVBgoCfWdwYi0hAF/RKJI+NtqwZ426oBPrB1Tc11poplRs9NcuzMBEfPTDJ6doLj56c4cX4qmZ6b4vXjYzz5xklOjk3X/UFXT2wM9hUY7C8w2NfDUJhf3ldgsK/AUH+yM1jWm9wGegthGrOsJ2ZZb4GB3ihp70na+wqRdh4iXUhB30K9hYhNq5Lx+yzlsnN2ssjpsWlOjye3U+NTnBkvcmYiuX9+ssjZieR2bnKa0bOT/OTN85ybLHJuojjzRXKj4sjoL0QM9Mb09yTB3xNH9BUiesN8byGiN47oKUT0xXPaw7Lq6YXLLEzjsCy531fjuXvj5BZF2vGIXKymBL2ZXQf8LyAG/trdv9iM1+lmUWQzQzWLVS4749MlxqZKjE+VGJsuzs5PlRibKs7MJ+sVmZguMz5dYmKqxGSxzFSpzFRx9nZuspjMV7VPV+ZL5XnfU1ysntgu3Amk7Hh65+2UZncqPQWjLzy2EEcUIqMQG4XIiKNoZr6yLI6MnjhZ1hPuJ+tExJX7kRFFNrP+bHtEbEYcnjOy2XVF2mXJg97MYuAvgX8KjABPmNked39xqV9L6osiY3lfMpzTKuWyM12u3gl42AmUmCr6vB1EZWcyXbXzmGmvsWzeDibcHxsrMlVypoql8Bif95h2MiPZAczbSUTEERfsRGbWsWQHE0c289jq5dU7lwt2OjV2NHF4zdhmp3FE1XyybvV6ccRMW1z13Bc8ZqaNeW3Vz1n9XNXPOTNfeY55bdpBLoVmJMAHgYPu/iqAmX0N2Ako6N8Cosjoi2L6Cp11aKm7Uyw7pbIzXSqHaXK/WC5TLM1fXmkvlZ3pslMM7eWq50rWm52v3C/PtJcplaFULif33SmF15p5nlJov+Cx5ZrPP1Uszz421Db72DLlMvMeW6mlHNbL27n84ho7k7k7iqjGTrSyo6z+VBXPaav+tFaIjZ7KNE4+FRbi5FNdIb5weaW9J46S78H6Cgz2Jd99DYbO1eplPR3znVczgn4TcKjq/gjwC014HZGGmVkYBuIt//sG9yTsS1XhX/JkhzA7z8xOqTSzg5jd4ZQvaEt/rpnl855/7msy01Yqz1kenqP69WvXnDxPqWpHN7OzCzvGYrnMRHH2eSs7+GIYdiyWk+l0qTyz/mKHIzeu7GewgU/T/+6abfzG+962qNdoVDOCvtYubN6WMrNbgVsB3v72tzehDBGpxcyILekpSzav+rRV2QFMh09706XyzPdd5yZLjE0WOT9V4uT5KZ4ZOUW5gR+kXsz3cI1qRtCPAFuq7m8GDs9dyd3vAu6C5JexTahDROSiWRjuKeT402AzfpL5BLDNzC41s17gJmBPE15HREQasOQ9encvmtlngO+RHF55j7u/sNSvIyIijWnKcXfu/gDwQDOeW0REFkZn0xIR6XIKehGRLqegFxHpcgp6EZEup6AXEelyHXEpQTMbBV5f5MPXAW8uYTlLpRPr6sSaoDPrUk2N68S6OrEmWPq63uHuw1krdUTQXwwz29vINRNbrRPr6sSaoDPrUk2N68S6OrEmaF9dGroREelyCnoRkS7XDUF/V7sLSNGJdXViTdCZdammxnViXZ1YE7SprtyP0YuISH3d0KMXEZE6ch30Znadmf3YzA6a2W0tfN0tZvawme03sxfM7LOh/c/M7Kdm9nS4XV/1mD8Jdf7YzH6tibW9ZmbPhdffG9rWmNmDZnYgTFeHdjOzO0Jdz5rZ1U2o5z1V2+NpMztjZp9rx7Yys3vM7JiZPV/VtuBtY2a7wvoHzGxXE2r672b2Unjdb5vZqtC+1czGq7bZX1U95v3hfT8Y6l70VUVSalrw+7XU/z9T6vp6VU2vmdnTob1V2yotC9r6dzWPu+fyRnIK5FeAy4Be4Bngiha99kbg6jA/BLwMXAH8GfDva6x/RaivD7g01B03qbbXgHVz2v4bcFuYvw24PcxfD3yX5KpgO4DHWvCe/Qx4Rzu2FfAR4Grg+cVuG2AN8GqYrg7zq5e4pmuBQpi/vaqmrdXrzXmex4FfDPV+F/jYEte0oPerGf8/a9U1Z/n/BP60xdsqLQva+nc195bnHv3MRcjdfQqoXIS86dz9iLs/GebPAvtJrpWbZifwNXefdPefAAdJ6m+VncDuML8buKGq/V5P/AhYZWYbm1jHNcAr7l7vx3FN21bu/ihwosbrLWTb/BrwoLufcPeTwIPAdUtZk7t/392L4e6PSK7SlirUtcLdf+hJatxb9e9YkprqSHu/lvz/Z726Qq/8nwF/W+85mrCt0rKgrX9Xc+U56GtdhLxe2DaFmW0FrgIeC02fCR/J7ql8XKO1tTrwfTPbZ8l1eQE2uPsRSP4wgfVtqAuSq41V/0ds97aChW+bVtf3r0l6gBWXmtlTZvZ/zezDVbWOtKCmhbxfrd5OHwaOuvuBqraWbqs5WdBRf1d5DvqGLkLe1ALMBoFvAZ9z9zPAncA7gSuBIyQfJaG1tX7I3a8GPgZ82sw+UmfdltVlyWUlPwH8XWjqhG1VT1odrdxmXwCKwH2h6Qjwdne/Cvg88DdmtqJFNS30/Wr1+/i7XNiJaOm2qpEFqaumvH5Tt1eeg76hi5A3i5n1kLyx97n73wO4+1F3L7l7Gfg/zA45tKxWdz8cpseAb4cajlaGZML0WKvrItnxPOnuR0N9bd9WwUK3TUvqC1/G/Trwe2GIgTA8cjzM7yMZA393qKl6eGfJa1rE+9Wy99HMCsBvAV+vqrdl26pWFtBhf1d5Dvq2XYQ8jAfeDex39y9VtVePb/8mUDk6YA9wk5n1mdmlwDaSL4SWuq7lZjZUmSf5Uu/58PqVb/F3AfdX1XVzOBJgB3C68nGzCS7ocbV7W1VZ6Lb5HnCtma0OwxfXhrYlY2bXAX8MfMLdx6rah80sDvOXkWybV0NdZ81sR/jbvLnq37FUNS30/Wrl/89fBV5y95khmVZtq7QsoNP+rpbqW9123Ei+wX6ZZG/9hRa+7i+TfKx6Fng63K4Hvgo8F9r3ABurHvOFUOePuYhv+TPquozk6IZngBcq2wRYCzwEHAjTNaHdgL8MdT0HbG9SXcuA48DKqraWbyuSHc0RYJqkB3XLYrYNybj5wXD7ZBNqOkgyXlv52/qrsO5vh/f1GeBJ4Deqnmc7Sfi+AvwF4ceQS1jTgt+vpf7/Wauu0P4V4PfnrNuqbZWWBW39u5p70y9jRUS6XJ6HbkREpAEKehGRLqegFxHpcgp6EZEup6AXEelyCnoRkS6noBcR6XIKehGRLvf/AV2RYlNTShJWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that from the 2034 topics, only a fraction really has a relevant weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us have a look at the 10 most relevant topics found by our model, we will represent a topic by the 8 most relevant words to that topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_topics(a, num_top_words=8):\n",
    "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_top_words-1:-1]]\n",
    "    topic_words = ([top_words(t) for t in a])\n",
    "    return [' '.join(t) for t in topic_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['critus ditto propagandist surname galacticentric kindergarten surreal imaginative',\n",
       " 'edu graphics data space pub mail 128 3d',\n",
       " 'space jesus launch god people satellite matthew atheists',\n",
       " 'space launch satellite commercial nasa satellites market year',\n",
       " 'jpeg graphics space pub edu ray mail send',\n",
       " 'jesus matthew prophecy messiah psalm isaiah david said',\n",
       " 'launch commercial satellite market image services satellites launches',\n",
       " 'data available nasa ftp grass anonymous contact gov',\n",
       " 'atheists god religious atheism religion believe belief atheist',\n",
       " 'probe data surface moon mars probes lunar launch']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(np.transpose(U)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these topics with the *\"original\"* topics to see whether the results are good. Remember that this is unsupervised learning, the topics below are just for reference and have at no point been given to our model as information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names #The original topics, for reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function below if you want to get more information on a specific topic. It gives you the number of top words you wish to see (default at 10) paired with their relevancy for the topic as well as a plot of those relevancies. Just put in the index of the topic you are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.37078708261541204, 'space'),\n",
       " (0.23469791756443883, 'jesus'),\n",
       " (0.21631027095973063, 'launch'),\n",
       " (0.2025332575252736, 'god'),\n",
       " (0.13461498333108898, 'people'),\n",
       " (0.13006103023944154, 'satellite'),\n",
       " (0.12307802293069604, 'matthew'),\n",
       " (0.10973025494563006, 'atheists'),\n",
       " (0.09707589568187676, 'does'),\n",
       " (0.08698909373485755, 'time')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def topic_details(t, num_top_words=10):\n",
    "    word_relev =  [(U[i,t],vocab[i]) for i in np.argsort(U[:,t])[:-num_top_words-1:-1]]\n",
    "    display = [U[i,t] for i in np.argsort(U[:,t])[:-num_top_words-1:-1]]\n",
    "    plt.plot(display)\n",
    "    return word_relev\n",
    "\n",
    "topic_details(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Truncated SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping the the relevancies of our topics in mind (plt.plot(S)), we can lose some of the less relevant topics, which translates into *truncating* our matrices $U, S$ and $V$. We get an approximate decomposition which uses way less space, called *Truncated SVD*. So we lose columns in $U$, singular values in $S$ and rows in $V$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](SVD_visualization.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens, if we reduce $U$ by $n$ colons (from the right), $S$ by $n$ singular values (the last/least ones) and $V$ by $n$ rows (from the buttom)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(n):\n",
    "    U1 = U[:,:-n]\n",
    "    S1 = S[:-n]\n",
    "    V1 = V[:-n,0:]\n",
    "    print(U1.shape, S1.shape, V1.shape)\n",
    "    print(\"relative average deviation:\" )\n",
    "    return np.mean(WordPerDoc - (U1 @ np.diag(S1) @ V1))/np.mean(WordPerDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26576, 34) (34,) (34, 2034)\n",
      "relative average deviation:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.035640196139667964"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncate(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when losing 2000 of 2034 topics ( >98%) we only deviate by about 3.5% in average. What about the top 10 topics we had before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26576, 10) (10,) (10, 2034)\n",
      "relative average deviation:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13880189087519487"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncate(2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the top 10 topics cover more than 86% of the information troughout all documents. Other than interpretability of the topics, the relative average deviation might be a good percentage to try to minimize when you're interested in a certain number of topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The runtime complexity of calculating the SVD of an $m \\times n$ matrix is $\\mathcal{O}(min(m^2n,n^2m))$. But as we saw above, we don't actually need to get all the topics. One way to drastically improve the performance with only a minor loss in accuracy is using randomized SVD, where you can decide upon the amount of topics you want to obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, v = decomposition.randomized_svd(WordPerDoc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26576, 10) (10,) (10, 2034)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.13880258998375353"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(u.shape,s.shape,v.shape)\n",
    "np.mean(u@np.diag(s)@v - WordPerDoc)/np.mean(WordPerDoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get an accuracy which is really close to where we computed the complete SVD and truncated it afterwards to the same number of topics. How do the topics in the randomized version look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jpeg image edu file graphics images gif data',\n",
       " 'jpeg gif file color quality image jfif format',\n",
       " 'space jesus launch god people satellite matthew atheists',\n",
       " 'space launch satellite commercial nasa satellites market year',\n",
       " 'image data processing analysis software available tools display',\n",
       " 'jesus matthew prophecy messiah psalm isaiah david said',\n",
       " 'launch commercial satellite market image services satellites launches',\n",
       " 'image probe surface lunar mars probes moon orbit',\n",
       " 'argument fallacy conclusion example true ad argumentum premises',\n",
       " 'space larson image theory universe physical nasa material']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(np.transpose(u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification\n",
    "\n",
    "The decomposition we have can not only give us a hold of the topics, in fact it comes with a decomposition right away.\n",
    "\n",
    "The following function takes the index of a document as input and outputs the most relevant topics (5 at default) by displaying the overall topic nr., the relevancy for the specific document and the most relevant words for each topic (8 at default).\n",
    "\n",
    "If details = True is set as a parameter, the relevancies of each word for a specific topic are also displayed and plotted.\n",
    "\n",
    "With the *truncate_to* parameter, it can be specified how many of the (overall) most relevant topics should be taken into account.\n",
    "\n",
    "Also *cl* should always be the matrix containing the topics-per-document matrix that takes the overall relevancies into account as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = np.diag(S)@V\n",
    "\n",
    "def show_classification(doc_index, num_top_words=8, num_topics=5, details=False, truncate_to=2000):\n",
    "    topic_indexes = np.argsort(np.transpose(cl)[doc_index, :truncate_to],axis=None)  #get the indexes of the topics in descending order (in terms of relevancy for the document)\n",
    "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_top_words-1:-1]] #function that takes topic as input and returns top num_top_words words\n",
    "    for i in range(num_topics): # i in [0,...,num_topics-1]\n",
    "        cur_topic = topic_indexes[-(i+1)] #cur_topic = (i+1)-th most relevant topic\n",
    "        print(str(i+1) +\".) Topic nr.\" + str(cur_topic) + \", relevancy for document:\" + str(cl[cur_topic,doc_index]))\n",
    "        if details:\n",
    "            print(topic_details(cur_topic, num_top_words=num_top_words))\n",
    "        else:\n",
    "            print(\"Top \" + str(num_top_words) + \" words:\") \n",
    "            print(' '.join(top_words(np.transpose(U)[cur_topic])))\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Sample data\n",
    "\n",
    "Let's have a look at some the In-Sample document first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "1.) Topic nr.383, relevancy for document:1.5076190369755713\n",
      "Top 8 words:\n",
      "read file koran linux mode given list interesting\n",
      "2.) Topic nr.343, relevancy for document:1.0248527983753972\n",
      "Top 8 words:\n",
      "aluminum video looking file polygon format email mr\n",
      "3.) Topic nr.88, relevancy for document:0.9361496911441157\n",
      "Top 8 words:\n",
      "bit cview xxxx sphinx believe does objective file\n",
      "4.) Topic nr.22, relevancy for document:0.8860415274564906\n",
      "Top 8 words:\n",
      "edu read display menu bits faq program pressing\n",
      "5.) Topic nr.259, relevancy for document:0.884972801501304\n",
      "Top 8 words:\n",
      "actually isn points know vesa file sun member\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(newsgroups_train.data[:1]))\n",
    "show_classification(0)\n",
    "#show_classification(0, details=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that the text-classification results are actually not overwhelming in the sense that we don't see right asway that this post is related to computer graphics. But when looking at the keywords, we can see that most of them are indeed related to computer graphics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-Sample data\n",
    "\n",
    "But what happens when we use out-of-sample data? Rememember that the data we used was split into training- and testing- data. \n",
    "We can use the same vectorizer as before to transform the test data into a matrix. Note that any new vocabulary is lost in the process, so we might lose information on the topics during this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26576, 1353) (26576, 2034)\n"
     ]
    }
   ],
   "source": [
    "WordPerDoc_test = np.transpose(vectorizer4.transform(newsgroups_test.data)) #transform the test data into a matrix, using the vocab of the previous transformation\n",
    "print(WordPerDoc_test.shape, WordPerDoc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we get the classification now? It is actually really easy. if we have a document *doc* which translates into a document vector $b$, what we actually want to do is solve for $x$ the linear equation:\n",
    "\n",
    "$b = Ux$\n",
    "\n",
    "$x$ will then have the relevancies of the topics for *doc*. Solving that linear equation is actually really easy, because the columns of $U$ are orhogonal (as mentioned earlier), which means that: transpose(U) @ U = Identity. So\n",
    "\n",
    "$x = transpose(U)b$\n",
    "\n",
    "Let's have a look at one of the posts we have in the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there,\n",
      "\n",
      "I am here looking for some help.\n",
      "\n",
      "My friend is a interior decor designer. He is from Thailand. He is\n",
      "trying to find some graphics software on PC. Any suggestion on which\n",
      "software to buy,where to buy and how much it costs ? He likes the most\n",
      "sophisticated \n",
      "software(the more features it has,the better)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(newsgroups_test.data[2:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the corresponding document vector is the corresponding columns in *WordPerDoc_test*, so the topic-per-document vector is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 802 ms\n"
     ]
    }
   ],
   "source": [
    "%time cl = np.transpose(U) @ WordPerDoc_test[:,2:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use function from before to have a look into that classification (it is important to set cl to the new topics-per-document vector/matrix for the function to work)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.) Topic nr.47, relevancy for document:0.8478543840578256\n",
      "Top 8 words:\n",
      "graphics search software data law april gif just\n",
      "2.) Topic nr.52, relevancy for document:0.5011777275556716\n",
      "Top 8 words:\n",
      "center graphics search software tax ssf vinge information\n",
      "3.) Topic nr.49, relevancy for document:0.4656111112236855\n",
      "Top 8 words:\n",
      "uci ics incoming gif software research ________________________________________________________________________________ center\n",
      "4.) Topic nr.34, relevancy for document:0.4186861927651059\n",
      "Top 8 words:\n",
      "lunar ________________________________________________________________________________ computer software material siggraph tele use\n",
      "5.) Topic nr.140, relevancy for document:0.40427539076272306\n",
      "Top 8 words:\n",
      "cost said evidence software moral printer postscript hit\n"
     ]
    }
   ],
   "source": [
    "show_classification(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the classification seems to work quite well in the out-of-sample case as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "SVD is a very useful tool to do topic modelling which implicitly gives you a lot of information. Depending on the use-case, different preprocessing should be done. At all times it should be kept in mind that this is an unsupervised learning model and you therefore have to be more flexible in interpreting the results as compared to supervised learning.\n",
    "\n",
    "There are other Matrix decompositions like Nonnegative Matrix Decompisition which can also be used for topic modelling but the fields of application are really only limited by your imagination, as SVD for instance can be used for background removal in videos and data compression.\n",
    "\n",
    "Matrix Decomposition in general is a very basic yet powerfull concept, that can be implemented using open source toolkits and libraries and have direct real life use cases without needing any sophisticated deep learning models. These kind of mathematical (Linear Algebra) concepts are the basic fundamentals of AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
